# Challenge T√©cnico ‚Äì Desarrollador Backend (Node.js)

## Descripci√≥n de la Soluci√≥n

Esta soluci√≥n implementa un microservicio backend en Node.js (NestJS) para procesar un archivo de clientes de gran tama√±o (`CLIENTES_IN_0425.dat`) y volcar sus datos en una base de datos SQL Server. Se ha dise√±ado pensando en la eficiencia de memoria y la escalabilidad, utilizando streams para el procesamiento del archivo y TypeORM para la gesti√≥n de la base de datos y migraciones.

**Caracter√≠sticas principales:**
*   **Procesamiento por Streams:** Lee el archivo l√≠nea por l√≠nea, sin cargarlo completamente en memoria, lo que permite manejar archivos de gran tama√±o con recursos limitados.
*   **Procesamiento por Lotes:** Los registros v√°lidos se agrupan en lotes para optimizar las inserciones masivas en SQL Server, reduciendo la sobrecarga de la base de datos.
*   **Manejo de Errores:** Las l√≠neas corruptas en el archivo son registradas y omitidas, permitiendo que el procesamiento contin√∫e sin interrupciones.
*   **Endpoint `/health`:** Un endpoint de salud (`GET /health`) que responde incluso durante el procesamiento del archivo, asegurando la operatividad del servicio.
*   **Migraciones de TypeORM:** La estructura de la tabla de clientes se gestiona mediante migraciones de TypeORM, facilitando el control de versiones del esquema de la base de datos.
*   **Contenedorizaci√≥n:** La aplicaci√≥n y la base de datos se ejecutan en contenedores Docker, facilitando el despliegue en entornos como Kubernetes.

## Requisitos Previos

Aseg√∫rate de tener instalado lo siguiente en tu sistema:

*   **Docker Desktop:** Para ejecutar la base de datos SQL Server y la aplicaci√≥n en contenedores.
*   **Node.js (v18 o superior) y npm:** Necesario si deseas ejecutar la aplicaci√≥n localmente (fuera de Docker) o para generar el archivo de prueba.

## üöÄ Gu√≠a de Inicio R√°pido (Usando Docker Compose)

Esta es la forma recomendada para levantar toda la soluci√≥n (base de datos y aplicaci√≥n) con un solo comando.

### 1. Configuraci√≥n del Entorno

Crea un archivo `.env` en la ra√≠z del proyecto (puedes usar `.env.example` como plantilla) y configura las variables de entorno para la conexi√≥n a la base de datos.

```bash
cp .env.example .env
# Edita .env con tus credenciales si son diferentes a las predeterminadas
```

### 2. Generar el Archivo de Prueba de Clientes

El proyecto incluye un script para generar el archivo `CLIENTES_IN_0425.dat` con datos aleatorios y errores intencionales.

```bash
npm install # Si no lo has hecho ya
npx ts-node generateFiles.ts # Aseg√∫rate de que el script se llama generateFiles.ts
```
Esto generar√° el archivo en la ra√≠z del proyecto (`CLIENTES_IN_0425.dat`).

### 3. Levantar la Soluci√≥n Completa

Utiliza `docker-compose.yml` para construir la imagen de la aplicaci√≥n, levantar el contenedor de SQL Server, ejecutar las migraciones de TypeORM y finalmente iniciar la aplicaci√≥n.

```bash
docker-compose up --build -d
```

Espera unos minutos hasta que ambos contenedores est√©n completamente operativos. Puedes verificar su estado con `docker-compose ps`.

La aplicaci√≥n estar√° disponible en `http://localhost:3000`.

## üõ†Ô∏è Ejecuci√≥n en Entorno de Desarrollo (App Local, DB en Docker)

Si prefieres ejecutar la aplicaci√≥n Node.js directamente en tu m√°quina local para facilitar el desarrollo y la depuraci√≥n, puedes seguir estos pasos:

### 1. Levantar la Base de Datos SQL Server (solo DB)

Utiliza el `docker-compose.db.yml` para iniciar √∫nicamente el contenedor de SQL Server. Este script `init.sql` crear√° el esquema `file_processor`.

```bash
docker-compose -f docker-compose.db.yml up -d
```

Espera unos minutos hasta que el contenedor de SQL Server est√© completamente operativo y saludable. Puedes verificar su estado con `docker-compose -f docker-compose.db.yml ps`.

### 2. Configuraci√≥n del Entorno Local

Aseg√∫rate de tener tu archivo `.env` configurado como se describe en el paso 1 de la "Gu√≠a de Inicio R√°pido".

### 3. Instalar Dependencias

```bash
npm install
```

### 4. Ejecutar Migraciones de TypeORM

Una vez que la base de datos est√© levantada, aplica las migraciones para crear la tabla `Clients`.

```bash
npm run typeorm:migration:run
```

### 5. Generar el Archivo de Prueba de Clientes

```bash
npx ts-node generateFiles.ts # Aseg√∫rate de que el script se llama generateFiles.ts
```
Esto generar√° el archivo en la ra√≠z del proyecto (`CLIENTES_IN_0425.dat`).

### 6. Iniciar la Aplicaci√≥n Localmente

```bash
npm run start:dev
```

La aplicaci√≥n estar√° disponible en `http://localhost:3000`.

## üì° Uso de la API

### Endpoint de Salud

Verifica que el servicio est√© operativo. Puedes ejecutar este comando en tu terminal:

```bash
curl http://localhost:3000/health
```

Respuesta esperada:
```json
{
  "status": "OK",
  "timeelapsed": "YYYY-MM-DDTHH:MM:SS.sssZ"
}
```

### Endpoint de Procesamiento de Archivos

Inicia el procesamiento del archivo de clientes. Este endpoint responde inmediatamente, y el procesamiento se realiza en segundo plano.

```bash
curl -X POST http://localhost:3000/file/process
```

Respuesta esperada:
```json
{
  "message": "Procesamiento de archivo iniciado en segundo plano."
}
```

Puedes monitorear los logs del contenedor de la aplicaci√≥n (si la corres con Docker Compose) para ver el progreso del procesamiento:

```bash
docker-compose logs -f app
```
O si la corres localmente, ver√°s los logs en tu terminal.

## üèóÔ∏è Arquitectura y Decisiones T√©cnicas

El proyecto sigue una arquitectura limpia (Clean Architecture), separando las responsabilidades en capas:
*   `src/file/domain`: Entidades de negocio y contratos (interfaces de repositorio).
*   `src/file/application`: Servicios de aplicaci√≥n (l√≥gica de procesamiento).
*   `src/file/infrastructure`: Implementaciones concretas (controladores, repositorios SQL Server, esquemas de TypeORM).

**Decisiones clave:**
*   **Procesamiento por Streams:** Para manejar archivos de gran tama√±o con eficiencia de memoria, el `FileService` lee el archivo l√≠nea por l√≠nea utilizando `fs.createReadStream` y `readline`.
*   **Procesamiento por Lotes:** Las inserciones en la base de datos se realizan en lotes para optimizar el rendimiento y reducir la carga en SQL Server.
*   **Manejo de Errores:** Las l√≠neas corruptas son detectadas, logueadas y omitidas, permitiendo que el procesamiento contin√∫e sin interrupciones.
*   **Validaci√≥n de Datos:** Se realizan validaciones estrictas en el `FileService` para asegurar la integridad de los datos antes de la inserci√≥n.
*   **Prevenci√≥n de Duplicados:** Se verifica la existencia de DNIs duplicados tanto dentro del mismo lote como en la base de datos antes de insertar nuevos registros.
*   **Monitoreo B√°sico:** Se incluyen logs informativos con m√©tricas de progreso, uso de memoria y CPU para observar el rendimiento del procesamiento.

## üìà Propuesta T√©cnica para Escalabilidad (Archivos 5 veces m√°s grandes)

Para manejar archivos de entrada significativamente m√°s grandes (ej. 5 GB), la estrategia actual de procesamiento de un solo archivo en un solo pod puede volverse un cuello de botella, incluso con streaming. Se propone una estrategia de **procesamiento distribuido y paralelizado**:

1.  **Servicio de Divisi√≥n de Archivos (File Splitter Service):**
    *   Un nuevo microservicio (o una funci√≥n serverless) ser√≠a responsable de recibir el archivo grande.
    *   Este servicio dividir√≠a el archivo de 5 GB en m√∫ltiples archivos m√°s peque√±os (ej. 50 archivos de 100 MB cada uno).
    *   Los archivos divididos se almacenar√≠an en un almacenamiento de objetos (ej. AWS S3, Azure Blob Storage) o un volumen compartido accesible por los pods de procesamiento.
    *   Tras la divisi√≥n, este servicio enviar√≠a mensajes a una cola de mensajes (ej. RabbitMQ, Kafka, SQS) para cada archivo peque√±o, indicando que est√° listo para ser procesado.

2.  **Escalamiento Horizontal del Servicio de Procesamiento:**
    *   El microservicio actual (`file-processor`) se configurar√≠a para escuchar mensajes de la cola.
    *   Cada instancia (pod) del `file-processor` tomar√≠a un mensaje de la cola, descargar√≠a el archivo peque√±o correspondiente del almacenamiento de objetos y lo procesar√≠a utilizando la l√≥gica de streaming y lotes ya implementada.
    *   En Kubernetes, se podr√≠a configurar un Horizontal Pod Autoscaler (HPA) basado en la longitud de la cola de mensajes o en el uso de CPU/memoria, para escalar autom√°ticamente el n√∫mero de pods de `file-processor` seg√∫n la carga de trabajo.

3.  **Base de Datos Escalable:**
    *   SQL Server puede escalar verticalmente (m√°s CPU/RAM) o, para cargas extremas, se podr√≠a considerar una arquitectura de base de datos distribuida o un servicio gestionado que ofrezca alta disponibilidad y escalabilidad (ej. Azure SQL Database, AWS RDS for SQL Server).
    *   Las inserciones masivas (`BULK INSERT`) ya son eficientes, pero con m√∫ltiples pods escribiendo simult√°neamente, es crucial que la base de datos pueda manejar la concurrencia.

**Beneficios de esta estrategia:**
*   **Paralelizaci√≥n:** M√∫ltiples pods procesan partes del archivo simult√°neamente, reduciendo dr√°sticamente el tiempo total de procesamiento.
*   **Resiliencia:** Si un pod falla, otro puede retomar el procesamiento de los archivos pendientes en la cola.
*   **Desacoplamiento:** Los servicios de divisi√≥n y procesamiento est√°n desacoplados, lo que permite escalar cada componente de forma independiente.
*   **Eficiencia de Recursos:** Cada pod sigue procesando archivos peque√±os con los mismos l√≠mites de memoria, manteniendo la eficiencia.

## Soporte

Para preguntas o soporte, por favor contacta al equipo de desarrollo.
